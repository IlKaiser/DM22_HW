{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all_gene_disease Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geneId</th>\n",
       "      <th>geneSymbol</th>\n",
       "      <th>DSI</th>\n",
       "      <th>DPI</th>\n",
       "      <th>diseaseId</th>\n",
       "      <th>diseaseName</th>\n",
       "      <th>diseaseType</th>\n",
       "      <th>diseaseClass</th>\n",
       "      <th>diseaseSemanticType</th>\n",
       "      <th>score</th>\n",
       "      <th>EI</th>\n",
       "      <th>YearInitial</th>\n",
       "      <th>YearFinal</th>\n",
       "      <th>NofPmids</th>\n",
       "      <th>NofSnps</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.538</td>\n",
       "      <td>C0001418</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "      <td>group</td>\n",
       "      <td>C04</td>\n",
       "      <td>Neoplastic Process</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>LHGDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.538</td>\n",
       "      <td>C0002736</td>\n",
       "      <td>Amyotrophic Lateral Sclerosis</td>\n",
       "      <td>disease</td>\n",
       "      <td>C18;C10</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BEFREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.538</td>\n",
       "      <td>C0003578</td>\n",
       "      <td>Apnea</td>\n",
       "      <td>phenotype</td>\n",
       "      <td>C23;C08</td>\n",
       "      <td>Sign or Symptom</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BEFREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.538</td>\n",
       "      <td>C0003864</td>\n",
       "      <td>Arthritis</td>\n",
       "      <td>disease</td>\n",
       "      <td>C05</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BEFREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.538</td>\n",
       "      <td>C0008373</td>\n",
       "      <td>Cholesteatoma</td>\n",
       "      <td>disease</td>\n",
       "      <td>C17</td>\n",
       "      <td>Disease or Syndrome</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BEFREE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geneId geneSymbol  DSI    DPI diseaseId                    diseaseName  \\\n",
       "0       1       A1BG  0.7  0.538  C0001418                 Adenocarcinoma   \n",
       "1       1       A1BG  0.7  0.538  C0002736  Amyotrophic Lateral Sclerosis   \n",
       "2       1       A1BG  0.7  0.538  C0003578                          Apnea   \n",
       "3       1       A1BG  0.7  0.538  C0003864                      Arthritis   \n",
       "4       1       A1BG  0.7  0.538  C0008373                  Cholesteatoma   \n",
       "\n",
       "  diseaseType diseaseClass  diseaseSemanticType  score   EI  YearInitial  \\\n",
       "0       group          C04   Neoplastic Process   0.01  1.0       2008.0   \n",
       "1     disease      C18;C10  Disease or Syndrome   0.01  1.0       2008.0   \n",
       "2   phenotype      C23;C08      Sign or Symptom   0.01  1.0       2017.0   \n",
       "3     disease          C05  Disease or Syndrome   0.01  1.0       2019.0   \n",
       "4     disease          C17  Disease or Syndrome   0.01  1.0       2020.0   \n",
       "\n",
       "   YearFinal  NofPmids  NofSnps  source  \n",
       "0     2008.0         1        0   LHGDN  \n",
       "1     2008.0         1        0  BEFREE  \n",
       "2     2017.0         1        0  BEFREE  \n",
       "3     2019.0         1        0  BEFREE  \n",
       "4     2020.0         1        0  BEFREE  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_gene_disease_associations.tsv\", sep='\\t', header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count most mentioned diseases\n",
    "In this way I can decide to focus on some relevant disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diseaseName</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20055</th>\n",
       "      <td>Neoplasms</td>\n",
       "      <td>10161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17952</th>\n",
       "      <td>Malignant Neoplasms</td>\n",
       "      <td>8621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23326</th>\n",
       "      <td>Primary malignant neoplasm</td>\n",
       "      <td>8221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18033</th>\n",
       "      <td>Malignant neoplasm of breast</td>\n",
       "      <td>6941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>Breast Carcinoma</td>\n",
       "      <td>6776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28471</th>\n",
       "      <td>Tumor Cell Invasion</td>\n",
       "      <td>6626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20027</th>\n",
       "      <td>Neoplasm Metastasis</td>\n",
       "      <td>6385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5519</th>\n",
       "      <td>Carcinogenesis</td>\n",
       "      <td>6243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16738</th>\n",
       "      <td>Liver carcinoma</td>\n",
       "      <td>5725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>Colorectal Carcinoma</td>\n",
       "      <td>5473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18081</th>\n",
       "      <td>Malignant neoplasm of prostate</td>\n",
       "      <td>4502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23597</th>\n",
       "      <td>Prostate carcinoma</td>\n",
       "      <td>4388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18060</th>\n",
       "      <td>Malignant neoplasm of lung</td>\n",
       "      <td>4173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>Carcinoma of lung</td>\n",
       "      <td>4081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20458</th>\n",
       "      <td>Non-Small Cell Lung Carcinoma</td>\n",
       "      <td>3926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23331</th>\n",
       "      <td>Primary malignant neoplasm of lung</td>\n",
       "      <td>3894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28478</th>\n",
       "      <td>Tumor Progression</td>\n",
       "      <td>3865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18089</th>\n",
       "      <td>Malignant neoplasm of stomach</td>\n",
       "      <td>3806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27117</th>\n",
       "      <td>Stomach Carcinoma</td>\n",
       "      <td>3720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18038</th>\n",
       "      <td>Malignant neoplasm of colon and/or rectum</td>\n",
       "      <td>3669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     diseaseName  count\n",
       "20055                                  Neoplasms  10161\n",
       "17952                        Malignant Neoplasms   8621\n",
       "23326                 Primary malignant neoplasm   8221\n",
       "18033               Malignant neoplasm of breast   6941\n",
       "4604                            Breast Carcinoma   6776\n",
       "28471                        Tumor Cell Invasion   6626\n",
       "20027                        Neoplasm Metastasis   6385\n",
       "5519                              Carcinogenesis   6243\n",
       "16738                            Liver carcinoma   5725\n",
       "7057                        Colorectal Carcinoma   5473\n",
       "18081             Malignant neoplasm of prostate   4502\n",
       "23597                         Prostate carcinoma   4388\n",
       "18060                 Malignant neoplasm of lung   4173\n",
       "5561                           Carcinoma of lung   4081\n",
       "20458              Non-Small Cell Lung Carcinoma   3926\n",
       "23331         Primary malignant neoplasm of lung   3894\n",
       "28478                          Tumor Progression   3865\n",
       "18089              Malignant neoplasm of stomach   3806\n",
       "27117                          Stomach Carcinoma   3720\n",
       "18038  Malignant neoplasm of colon and/or rectum   3669"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top 20 gene symbols per disease\n",
    "df.groupby(\"diseaseName\")[\"geneSymbol\"].count()\\\n",
    ".reset_index(name='count')\\\n",
    ".sort_values(['count'], ascending=False)\\\n",
    ".head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Information\n",
    "Now it is necessary to retrieve information about genes for the chosen disease, in my case the **Liver carcinoma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gene list in order to label datas\n",
    "gene_list = df[df[\"diseaseName\"] == \"Breast Carcinoma\"][\"geneSymbol\"].drop_duplicates()\n",
    "gene_list = list(gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAT1', 'NAT2', 'SERPINA3', 'AADAC', 'AAMP', 'AANAT', 'AARS1', 'ABCA1', 'ABCB7', 'ABCF1']\n"
     ]
    }
   ],
   "source": [
    "# Display some genes\n",
    "print(gene_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Protein-Protein Interaction Dataset\n",
    "Import the edge list as a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi = nx.Graph()\n",
    "edges = nx.read_edgelist(\"Biogrid_REDUX.txt\")\n",
    "ppi.add_edges_from(edges.edges())\n",
    "\n",
    "ppi.remove_edges_from(nx.selfloop_edges(ppi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Nodes: 4263\n",
      "# Edges: 8048\n"
     ]
    }
   ],
   "source": [
    "print(\"# Nodes: \"+str(len(ppi.nodes)))\n",
    "print(\"# Edges: \"+str(len(ppi.edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label PPI dataset\n",
    "Now if a protein of the list is present we put a 1 else a 0 (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 129 ms, sys: 3.03 ms, total: 132 ms\n",
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not exists(\"embeddings.emb\"):\n",
    "    # Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
    "    node2vec = Node2Vec(ppi, dimensions=64, walk_length=30, num_walks=200, workers=8)  # Use temp_folder for big graphs\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4) \n",
    "    model.wv.save_word2vec_format(\"embeddings.emb\") # save to file\n",
    "    wv = model.wv\n",
    "else:\n",
    "    wv = KeyedVectors.load_word2vec_format(\"embeddings.emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63583446  0.525262   -0.34538925  0.57825655  0.8907158   0.5654882\n",
      " -0.26057857  0.6535204   0.5753911   0.6911421   1.2430465  -0.36121282\n",
      "  1.1483617   0.73211974  0.32190344  0.46187016 -0.10312456  0.3932408\n",
      " -0.48767945  0.8974888   0.10346386  0.04698331 -1.1213664   0.2169608\n",
      " -0.09109395  0.02253432 -1.3750547  -0.5455049  -0.07808261  0.9353021\n",
      "  0.42966533  0.04327953 -0.2205511   1.7838341  -1.2173454   0.35714692\n",
      " -0.6283102  -0.89529127 -0.33630967  1.4640279   0.31301457 -0.39921093\n",
      " -0.09956352  0.87092555  0.17457898  0.49883142  0.7619757  -1.9879476\n",
      "  0.53596     0.33951506  0.00223186  0.01537907 -0.47599903  0.8532833\n",
      "  0.48313928  0.29452464  0.20674841 -0.22297807 -0.05739726 -0.90841645\n",
      " -1.1654633   0.08074023 -0.23202483 -0.598518  ]\n"
     ]
    }
   ],
   "source": [
    "# Display some data\n",
    "print(wv[\"A1BG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve node embeddings and corresponding subjects\n",
    "node_ids = wv.index_to_key  # list of node IDs\n",
    "node_embeddings = (\n",
    "    wv.vectors\n",
    ")  # numpy.ndarray of size number of nodes times embeddings dimensionality\n",
    "#node_targets = node_subjects[[int(node_id) for node_id in node_ids]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4263, 64)\n"
     ]
    }
   ],
   "source": [
    "# Shape of embeddings\n",
    "print(node_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 1 1 1]\n",
      "6775\n",
      "Positive to total ratio: 46.19%\n"
     ]
    }
   ],
   "source": [
    "# Label the nodes according to disease chosen\n",
    "labels = []\n",
    "for key in ppi.nodes():\n",
    "    if key in gene_list:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "labels = np.array(labels)\n",
    "print(labels)\n",
    "print(len(gene_list))\n",
    "print(\"Positive to total ratio: \"+\"{:.2f}\".format( (labels == 1).sum() / len(labels) *100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train machine learing model\n",
    "With embeddings and labels it is now possible to train a machine learing model. I will try first with **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_172363/371238870.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# New models imports skl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# New models imports skl\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Node 2 Vec nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data = from_networkx(ppi)\n",
    "\n",
    "model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=20,\n",
    "             context_size=10, walks_per_node=10,\n",
    "             num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
    "\n",
    "loader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
    " \n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    z = model()\n",
    "    acc = model.test(z[data.train_mask], data.y[data.train_mask],\n",
    "                     z[data.test_mask], data.y[data.test_mask],\n",
    "                     max_iter=10)\n",
    "    return acc\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, 71)):\n",
    "    loss = train()\n",
    "    #acc = test()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensor to numpy\n",
    "node_embeddings = z.detach().cpu().numpy()\n",
    "print(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "node_embeddings = scaler.fit_transform(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename sets\n",
    "X = node_embeddings\n",
    "\n",
    "Y = [1 if node in gene_list else 0 for node in ppi.nodes()]\n",
    "print(\"Positive to total ratio: \"+\"{:.2f}\".format( list(Y).count(1) / len(Y) *100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset split\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 42)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "#scores = cross_val_score(clf, X, Y, cv=5)\n",
    "#print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(x_train,y_train)\n",
    "#clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=3000).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "class Feedforward(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            hidden = self.fc1(x)\n",
    "            relu = self.relu(hidden)\n",
    "            output = self.fc2(relu)\n",
    "            output = self.sigmoid(F.linear(output))\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = torch.nn.Linear(128, 256) \n",
    "        self.layer_2 = torch.nn.Linear(256, 256)\n",
    "        self.layer_out = torch.nn.Linear(256, 1) \n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm1d(256)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(256)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nx stuff\n",
    "adj = nx.to_scipy_sparse_matrix(ppi).tocoo()\n",
    "row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
    "col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
    "edge_index = torch.stack([row,col],dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P2PDataset(InMemoryDataset):\n",
    "    def __init__(self,transform = None):\n",
    "        super(P2PDataset,self).__init__(\".\",transform,None,None)\n",
    "        data = Data(edge_index = edge_index)\n",
    "\n",
    "        data.num_nodes = ppi.number_of_nodes()\n",
    "\n",
    "        data.x = torch.from_numpy(node_embeddings).type(torch.float32)\n",
    "\n",
    "        y = torch.from_numpy(labels).type(torch.long)\n",
    "\n",
    "        data.y = y.clone().detach()\n",
    "\n",
    "        data.num_classes = 2\n",
    "\n",
    "\n",
    "        data[\"x_train\"] = x_train\n",
    "        data[\"x_test\"]  = x_test\n",
    "        data[\"x_val\"]   = x_val\n",
    "\n",
    "        self.data, self.slices = self.collate([data])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_val   = x_val.to(device)\n",
    "y_val   = y_val.to(device)\n",
    "x_test  = x_test.to(device)\n",
    "y_test  = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p = P2PDataset()\n",
    "model = BinaryClassification()\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#criterion = torch.nn.BCELoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = model(x_test)\n",
    "before_train = criterion(y_pred.squeeze(), y_test)\n",
    "print('Test loss before training' , before_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "val_values = []\n",
    "epoch = []\n",
    "epochs = 25\n",
    "for i in tqdm(range(epochs)):\n",
    "    print(\"{:.2f}\".format( i / (epochs-1) * 100) + \"%\",end='\\r')\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "            \n",
    "            '''\n",
    "            prediction = model(inputs)\n",
    "            loss = criterion(prediction.squeeze(), outputs) \n",
    "            #print('train loss')\n",
    "            #print(loss,end='\\r')\n",
    "            loss_values.append(loss.detach())\n",
    "            optimizer.zero_grad() #zero the parameter gradients\n",
    "            epoch.append(i)\n",
    "            loss.backward()       #compute gradients(dloss/dx)\n",
    "            optimizer.step()      #updates the parameters\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            y_pred = model(x_train)\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_pred.squeeze(), y_train)\n",
    "            acc = binary_acc(y_pred, y_train.unsqueeze(1))\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "            print('Epoch {}: train loss: {} Acc: {}'.format(epoch, loss.item(),epoch_acc))\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        elif phase == 'val':\n",
    "            model.eval()\n",
    "            \n",
    "            '''\n",
    "            prediction_val = model(inputs_val)\n",
    "            loss_val = criterion(prediction_val.squeeze(), outputs_val) \n",
    "            #print('validation loss')\n",
    "            #print(loss,end='\\r')\n",
    "            val_values.append(loss_val.detach())\n",
    "            optimizer.zero_grad() #zero the parameter gradients\n",
    "            '''\n",
    "            \n",
    "            # Forward pass\n",
    "            y_pred = model(x_val)\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_pred.squeeze(), y_val)\n",
    "            print('Epoch {}: validation loss: {}'.format(epoch, loss.item()))\n",
    "            optimizer.zero_grad()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = model(x_test)\n",
    "after_train = criterion(y_pred.squeeze(), y_test) \n",
    "print('Test loss after Training' , after_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binary_acc(y_pred.squeeze(),y_test).item(),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats\n",
    "Display report after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats imports\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.round(torch.sigmoid(y_pred.squeeze())).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test.cpu(), y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.cpu(), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN model\n",
    "Now we will proceed to create a GNN model in order to compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
